{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Two separate layers of RNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# embedding_dim = 128\n",
    "# class Encoder2Layer(nn.Module):\n",
    "#     def __init__(self, seq_len, n_features, n_layers):\n",
    "#         super(Encoder2Layer, self).__init__()\n",
    "#         self.seq_len = seq_len\n",
    "#         self.n_features = n_features\n",
    "#         self.n_layers = n_layers\n",
    "#         self.hidden_dim = 2 * embedding_dim\n",
    "#         self.rnn1 = nn.LSTM(\n",
    "#             input_size=self.n_features,\n",
    "#             hidden_size=self.hidden_dim,\n",
    "#             num_layers=self.n_layers,\n",
    "#             batch_first=True\n",
    "#         )\n",
    "#         self.rnn2 = nn.LSTM(\n",
    "#             input_size=self.hidden_dim,\n",
    "#             hidden_size=embedding_dim,\n",
    "#             num_layers=self.n_layers,\n",
    "#             batch_first=True\n",
    "#         )\n",
    "#     def forward(self, x):\n",
    "#         # x: (4, 16, 64)\n",
    "#         batch_size = x.shape[0]\n",
    "#         x, _ = self.rnn1(x) # (4, 16, 128)\n",
    "#         print(f'After first RNN, output shape: {x.shape}')\n",
    "#         x, (hidden, _) = self.rnn2(x)\n",
    "#         # (batch_size, seq_len, embedding_dim)\n",
    "#         print(f'After second RNN, output shape: {x.shape}') # (4, 16, 128)\n",
    "#         # (n_layers, batch_size, embedding_dim)\n",
    "#         print(f'After second RNN, hidden state shape: {hidden.shape}') # (1, 4, 128)\n",
    "#         return hidden.reshape(batch_size, -1)\n"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# x = torch.rand(4, 16, 64)\n",
    "# encoder = Encoder2Layer(seq_len=16, n_features=64, n_layers=1)\n",
    "# out = encoder(x)\n",
    "# out.shape"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# class Decoder2Layer(nn.Module):\n",
    "#     def __init__(self, seq_len, n_features, n_layers):\n",
    "#         super(Decoder2Layer, self).__init__()\n",
    "#         self.seq_len = seq_len\n",
    "#         self.n_features = n_features\n",
    "#         self.n_layers = n_layers\n",
    "#         self.hidden_dim = 2 * embedding_dim\n",
    "#         self.rnn1 = nn.LSTM(\n",
    "#             input_size=embedding_dim,\n",
    "#             hidden_size=embedding_dim,\n",
    "#             num_layers=self.n_layers,\n",
    "#             batch_first=True\n",
    "#         )\n",
    "#         self.rnn2 = nn.LSTM(\n",
    "#             input_size=embedding_dim,\n",
    "#             hidden_size=self.hidden_dim,\n",
    "#             num_layers=self.n_layers,\n",
    "#             batch_first=True\n",
    "#         )\n",
    "#         self.fc = nn.Linear(self.hidden_dim, self.n_features)\n",
    "#     def forward(self, x):\n",
    "#         # x: (batch_size, embedding_dim)\n",
    "#         x = x.repeat(self.seq_len, 1)\n",
    "#         print(f'After repeat, x shape: {x.shape}')\n",
    "#         x = x.reshape(4, self.seq_len, embedding_dim)\n",
    "#         print(f'After reshaping, x shape: {x.shape}')\n",
    "#         x, (hidden, cell) = self.rnn1(x)\n",
    "#         print(f'After first RNN, output shape: {x.shape}') # (4, 16, 128)\n",
    "#         print(f'After first RNN, hidden state shape: {hidden.shape}')\n",
    "#         x, (hidden, cell) = self.rnn2(x)\n",
    "#         print(f'After second RNN, output shape: {x.shape}') # (4, 16, 128)\n",
    "#         print(f'After second RNN, hidden state shape: {hidden.shape}')\n",
    "#         x = torch.squeeze(x)\n",
    "#         x = self.fc(x)\n",
    "#         return x"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# decoder = Decoder2Layer(seq_len=16, n_features=64, n_layers=1)\n",
    "# dec_out = decoder(out)\n",
    "# dec_out.shape"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Single layer of RNN"
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# embedding_dim = 128\n",
    "# class Encoder(nn.Module):\n",
    "#     def __init__(self, seq_len, n_features, n_layers):\n",
    "#         super(Encoder, self).__init__()\n",
    "#         self.seq_len = seq_len\n",
    "#         self.n_features = n_features\n",
    "#         self.n_layers = n_layers\n",
    "#         self.hidden_dim = 4*embedding_dim\n",
    "#         self.rnn = nn.LSTM(\n",
    "#             input_size=self.n_features,\n",
    "#             hidden_size=self.hidden_dim,\n",
    "#             num_layers=self.n_layers,\n",
    "#             batch_first=True\n",
    "#         )\n",
    "#     def forward(self, x):\n",
    "#         # x: (4, 16, 64)\n",
    "#         batch_size = x.shape[0]\n",
    "#         _, (hidden, _) = self.rnn(x)\n",
    "#         # (num_layers, batch_size, hidden_dim)\n",
    "#         print(f'After RNN, hidden size: {hidden.shape}')    # (2, batch_size, hidden_size)\n",
    "\n",
    "#         return hidden.reshape(batch_size, -1)"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# x = torch.rand(4, 16, 64)\n",
    "# encoder = Encoder(seq_len=16, n_features=64, n_layers=1)\n",
    "# out = encoder(x)\n",
    "# out.shape"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# class Decoder(nn.Module):\n",
    "#     def __init__(self, seq_len, n_features, n_layers):\n",
    "#         super(Decoder, self).__init__()\n",
    "#         self.seq_len = seq_len\n",
    "#         self.n_features = n_features\n",
    "#         self.n_layers = n_layers\n",
    "#         self.hidden_dim = 4*embedding_dim\n",
    "#         self.rnn = nn.LSTM(\n",
    "#             input_size=self.n_layers*self.hidden_dim,\n",
    "#             hidden_size=embedding_dim,\n",
    "#             num_layers=self.n_layers,\n",
    "#             batch_first=True\n",
    "#         )\n",
    "#         self.fc = nn.Linear(embedding_dim, self.n_features)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         # x: (batch_size, embedding_dim)\n",
    "#         x = x.repeat(1, self.seq_len, 1)\n",
    "#         print(f'After repeat, x shape: {x.shape}')\n",
    "#         x = x.reshape(4, self.seq_len, self.n_layers*self.hidden_dim)\n",
    "#         print(f'After reshaping, x shape: {x.shape}')\n",
    "#         x, (hidden, cell) = self.rnn(x)\n",
    "#         print(f'After first RNN, output shape: {x.shape}') # (4, 16, 128)\n",
    "#         print(f'After first RNN, hidden state shape: {hidden.shape}')\n",
    "#         x = torch.squeeze(x)\n",
    "#         x = self.fc(x)\n",
    "#         return x        "
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# decoder = Decoder(seq_len=16, n_features=64, n_layers=1)\n",
    "# dec_out = decoder(out)\n",
    "# dec_out.shape"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self, args, seq_len, n_features, n_layers, dropout, batch_size\n",
    "    ):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.args = args\n",
    "        self.seq_len = seq_len\n",
    "        self.n_features = n_features\n",
    "        self.hidden_dim = self.args.hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.batch_size = batch_size\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=self.n_features,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            batch_first=True,\n",
    "            num_layers=self.n_layers,\n",
    "            dropout=self.dropout,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = self.batch_size\n",
    "        _, (hidden, _) = self.rnn(x)\n",
    "        # hidden size: (num_layers, batch_size, hidden_size)\n",
    "        # hidden = hidden.reshape(\n",
    "        #     batch_size, -1\n",
    "        # )  # (batch_size, num_layers*hidden_size)\n",
    "        hidden = hidden.transpose(0, 1).contiguous().view(\n",
    "            -1, self.n_layers*self.hidden_dim\n",
    "        )\n",
    "        return hidden\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, args, seq_len, n_features, n_layers, dropout, batch_size\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.args = args\n",
    "        self.seq_len = seq_len\n",
    "        self.n_features = n_features\n",
    "        self.hidden_dim = self.args.hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.batch_size = batch_size\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=self.n_layers * self.hidden_dim,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            batch_first=True,\n",
    "            num_layers=self.n_layers,\n",
    "            dropout=self.dropout,\n",
    "        )\n",
    "        self.fc = nn.Linear(self.hidden_dim, self.n_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, num_layers*hidden_size)\n",
    "        x = x.repeat(1, self.seq_len, 1)\n",
    "        x = x.reshape(\n",
    "            -1, self.seq_len, self.n_layers * self.hidden_dim\n",
    "        )\n",
    "        x, _ = self.rnn(x)  # x: (batch_size, seq_len, hidden_dim)\n",
    "        x = self.fc(x)  # x: (batch_size, seq_len, n_features)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class LSTMAutoencoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(LSTMAutoencoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "        assert (\n",
    "            encoder.hidden_dim == decoder.hidden_dim\n",
    "        ), \"Hidden dimensions for both encoder and decoder must be equal\"\n",
    "\n",
    "        assert (\n",
    "            encoder.n_layers == decoder.n_layers\n",
    "        ), \"Encoder and decoder should have same number of layers\"\n",
    "\n",
    "    def forward(self, input):\n",
    "        # input = torch.unsqueeze(input, 0)\n",
    "        # encode\n",
    "        hidden = self.encoder(input)\n",
    "        # decode\n",
    "        y = self.decoder(hidden)\n",
    "\n",
    "        return y.squeeze(0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "X_valid = np.load('X_valid.npy')\n",
    "y_valid = np.load('y_valid.npy')\n",
    "X_valid = torch.as_tensor(X_valid, dtype=torch.float32)\n",
    "y_valid = torch.as_tensor(y_valid, dtype=torch.long)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_valid, y_valid)\n",
    "print(test_dataset.__getitem__(0)[0].shape)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([16, 64])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args('')\n",
    "args.hidden_size = 32\n",
    "args.device = 'cuda'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "seq_len = 16\n",
    "n_features = 64\n",
    "n_layers = 2\n",
    "pct = 0.3\n",
    "encoder = Encoder(\n",
    "    args,\n",
    "    seq_len=seq_len,\n",
    "    n_features=n_features,\n",
    "    n_layers=n_layers,\n",
    "    dropout=pct,\n",
    "    batch_size=1\n",
    ")\n",
    "decoder = Decoder(\n",
    "    args,\n",
    "    seq_len=seq_len,\n",
    "    n_features=n_features,\n",
    "    n_layers=n_layers,\n",
    "    dropout=pct,\n",
    "    batch_size=1\n",
    ")\n",
    "model = LSTMAutoencoder(encoder, decoder)\n",
    "model = model.to(args.device)\n",
    "model"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LSTMAutoencoder(\n",
       "  (encoder): Encoder(\n",
       "    (rnn): LSTM(64, 32, num_layers=2, batch_first=True, dropout=0.3)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (rnn): LSTM(64, 32, num_layers=2, batch_first=True, dropout=0.3)\n",
       "    (fc): Linear(in_features=32, out_features=64, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "model = torch.load('lstm_ae.pth')\n",
    "model = model.to(args.device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "model"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LSTMAutoencoder(\n",
       "  (encoder): Encoder(\n",
       "    (rnn): LSTM(64, 32, num_layers=2, batch_first=True, dropout=0.3)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (rnn): LSTM(64, 32, num_layers=2, batch_first=True, dropout=0.3)\n",
       "    (fc): Linear(in_features=32, out_features=64, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "model.eval()\n",
    "seq, _ = next(iter(test_loader))\n",
    "# seq = torch.unsqueeze(seq, 0)\n",
    "print(seq.shape)\n",
    "seq = seq.to(args.device)\n",
    "seq_pred = model(seq)\n",
    "print(seq_pred.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 16, 64])\n",
      "torch.Size([16, 64])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "with torch.no_grad():\n",
    "    mae = []\n",
    "    for data in test_loader:\n",
    "        seq = data[0]\n",
    "        seq = seq.to(args.device)\n",
    "        pred_seq = model(seq)\n",
    "        loss = torch.sum(torch.abs(torch.squeeze(seq, 0) - pred_seq))\n",
    "        mae.append(loss.cpu().numpy())\n",
    "error_df = pd.DataFrame(\n",
    "    {\"Reconstruction_error\": mae, \"Ground_truth\": y_valid.tolist()}\n",
    ")\n",
    "print(error_df)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     Reconstruction_error  Ground_truth\n",
      "0                22.28201             0\n",
      "1               22.173965             0\n",
      "2               22.230276             0\n",
      "3               22.294802             0\n",
      "4               22.253998             0\n",
      "...                   ...           ...\n",
      "6728            16.939283             0\n",
      "6729            17.069946             0\n",
      "6730            17.401886             0\n",
      "6731             17.23662             0\n",
      "6732            17.157166             0\n",
      "\n",
      "[6733 rows x 2 columns]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "error_df[error_df['Ground_truth'] == 1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reconstruction_error</th>\n",
       "      <th>Ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>30.741676</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>30.697445</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>30.76849</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>30.574942</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>30.21465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5901</th>\n",
       "      <td>151.29599</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5902</th>\n",
       "      <td>149.03806</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5903</th>\n",
       "      <td>146.76474</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5904</th>\n",
       "      <td>145.10883</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5905</th>\n",
       "      <td>143.5772</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>527 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Reconstruction_error  Ground_truth\n",
       "1547            30.741676             1\n",
       "1548            30.697445             1\n",
       "1549             30.76849             1\n",
       "1550            30.574942             1\n",
       "1551             30.21465             1\n",
       "...                   ...           ...\n",
       "5901            151.29599             1\n",
       "5902            149.03806             1\n",
       "5903            146.76474             1\n",
       "5904            145.10883             1\n",
       "5905             143.5772             1\n",
       "\n",
       "[527 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2bfb2b0ea0da4a047e5353e25c51f55b6197a3c49af393cf43578836a4a6fc3d"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('torch': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}